---
title: "Mesurer la quantité d'information"
author:
  - name: Marie-Pierre Etienne
    affiliation: 
      - ENSAI - CREST
    email: marie-pierre.etienne@ensai.fr
date: "Last updated on `r format(Sys.time(), '%d %B, %Y')`"
institute: https://marieetienne.github.io/MAF/
execute: 
  freeze: true
editor: 
  markdown: 
    wrap: 72
css: mpe_pres_revealjs.css
format:
  revealjs: 
    theme: [default, custom.scss]
    width: 1050
    margin: 0.05
    slide-number: true
    slide-level: 2
    show-slide-number: print
    menu:
      useTextContentForMissingTitles: false
    mathjax: true  # Active MathJax
    self-contained: true
---

```{r setup, include=FALSE, eval = TRUE}
library(RefManageR)
library(tidyverse) ## to benefit from the tidyverse coding system
library(reticulate) ## to use python from R
library(wesanderson)
library(plotly)
library(ggforce)
```

```{r reference,  include=FALSE, cache=FALSE, eval = TRUE}
BibOptions(check.entries = FALSE,
           bib.style = "authoryear",
           cite.style = "alphabetic",
           style = "markdown",
           hyperlink = FALSE,
           dashed = FALSE)
myBib <- ReadBib("./MAF.bib", check = FALSE)
theme_set(theme_minimal())
options(ggplot2.discrete.colour=   scale_color_manual(values = wesanderson::wes_palette(name = "Darjeeling1")) )
couleur <-  wesanderson::wes_palette(name = "Darjeeling1")
scale2 <- function(x, na.rm = FALSE) (x - mean(x, na.rm = na.rm)) / ( sqrt((length(x)-1) / length(x)) *sd(x, na.rm) )

```

::: hidden
\$\$

\newcommand\R{{\mathbb{R}}}
\newcommand\Xbf{{\boldsymbol{X}}}
\newcommand\norm[1]{\lVert#1\rVert}
\newcommand\xcol[1]{\boldsymbol{x}^{#1}}
\newcommand\xrow[1]{\boldsymbol{x}_{#1}}
\newcommand\xbf{\boldsymbol{x}}
\newcommand\ybf{\boldsymbol{y}}

\$\$
:::

```{r datapackage, eval = TRUE, echo = FALSE, warning = FALSE}
library(plotly)
ggplot <- function(...) ggplot2::ggplot(...) + scale_fill_manual(values = wesanderson::wes_palette(name = "Darjeeling1")) + scale_color_manual(values = wesanderson::wes_palette(name = "Darjeeling1")) + theme_minimal()
data(penguins, package = 'palmerpenguins')
penguins <- penguins %>% na.omit() %>% 
  mutate(year = as.factor(year))

```


# Une mesure de la quantité d'information contenue dans un nuage de points

## L'inertie par rapport à un point

::: {.callout-note icon="false" appearance="minimal"}
### Definition 1

L'inertie *par rapport à un point*
$a \in {\mathbb{R}}^{p}$ est définie par\
$$I_{\boldsymbol{a}} = \frac{1}{n} \sum_{i=1}^n \lVert\boldsymbol{x}_{i} - \boldsymbol{a}\rVert^2 = \frac{1}{n} \sum_{i=1}^n\sum_{k=1}^p  (x_i^k -a^k)^2$$
:::

::: panel-tabset
### Intuitivement

L'inertie par rapport à un point quantifie l'information perdue lorsque
le jeu de données est résumé par ce point.

[Quel est selon vous le point $\boldsymbol{a}$ qui minimise l'inertie
?]{.rouge}

$$argmin_{\boldsymbol{a}} I_{\boldsymbol{a}} = ??$$

### Réponse

[BINGO !!!]{.rouge}

Il s'agit du point
$\boldsymbol{g}=\boldsymbol{x_{\bullet}}=({x}_{\bullet}^1, \ldots, {x}_{\bullet}^p )^\top,$
avec ${x}_{\bullet}^k=\frac{1}{n} \sum_{i=1}^n x_{i}^k$, la valeur
moyenne de la variable $k$ sur l'ensemble des individus.

Puisque nous avons supposé que nos variables étaient centrées, $G=O$
l'origine sur repère.

### Théorème de Huyghens

$$\forall \boldsymbol{a}\in\mathbb{R}^p,\; I_\boldsymbol{a}=I_\boldsymbol{g} + \lVert\boldsymbol{a}- \boldsymbol{g}\rVert^2.$$

:::


## L'inertie par rapport à un point

::: {.callout-note icon="false" appearance="minimal"}
### Definition 2
L'inertie *du nuage de points* représentés par $\Xbf$ est l'inertie par rapport à son baycentre
$$I = \frac{1}{n} \sum_{i=1}^n \lVert\boldsymbol{x}_{i} - {g}\rVert^2 = \frac{1}{n} \sum_{i=1}^n\sum_{k=1}^p  (x_i^k -\bar{x}^k)^2$$

:::

[Conséquence]{.rouge}

Le meilleur résumé du nuage de points à un unique point est le
barycentre du nuage de points, c'est à dire la moyenne sur chacune des
dimensions. 

La quantité d'information perdue lors de ce résumé est $I$

### Remarque {#sec-inertie}

$$ I = \frac{1}{n}  \sum_{i=1}^n     \left( \sum_{k=1}^p \left( x_{i}^k - x_{\bullet}^k  \right)^2 \right)  = \sum_{k=1}^p  \left( \frac{1}{n}  \sum_{i=1}^n  \left( x_{i}^k - x_{\bullet}^k  \right)^2 \right)  = \sum_{k=1}^p  Var(\boldsymbol{x}^{k})$$
Si les variables sont réduites, i.e de norme 1

$$I = p$$

## L'inertie par rapport à un axe

::: {.callout-note icon="false" appearance="minimal"}
### Definition 2

L'inertie *par rapport à l'axe* $\Delta$ est définie par

$$I_{\boldsymbol{\Delta}} = \frac{1}{n} \sum_{i=1}^n \lVert\boldsymbol{x}_{i} - \boldsymbol{p_i}^{\Delta}\rVert^2 = \frac{1}{n} \sum_{i=1}^n\sum_{k=1}^p  (x_i^k -p^{k,\Delta}_i)^2, \quad \mbox{où }\  \boldsymbol{p_i}^{\Delta} \mbox{projeté orthogonal de } \boldsymbol{x_i} \mbox{ sur }\Delta.$$


:::

{Rajouter un exemple avec des projections sur les axes de départ}[.rouge]

::::::::: panel-tabset
### Intuitivement

::::: columns
::: {.column width="30%"}
L'inertie par rapport à l'axe $\Delta$ quantifie l'information perdue
lorsque l'on résume le nuage de points à son projeté sur $\Delta$.
:::

::: {.column width="65%"}
```{r inertie_delta}

individus <- data.frame(
  x = c(1.5, -0.5, -1),   # Coordonnées des points individuels
  y = c(0.9, 1, -0.5)
)

u = c(1,2)
norme_u = sum(u^2)

ind_proj <- (as.matrix(individus)%*% as.matrix(u, ncol= 1)/(norme_u)) %*% matrix(u, ncol = 2, nrow=1)
ind_proj <- as.data.frame(ind_proj) %>% 
  rename(xend= V1, yend=V2)
individus_dessin <- cbind(individus, ind_proj) %>% as.data.frame()

# Schéma avec ggplot
ggplot() +
  
  # Tracer Delta
   geom_segment(aes(x = -1, y = -2, xend = 1, yend = 2), arrow = arrow(length = unit(0.3, "cm")), size = 0.5) +  # Axe vertical
  
  # Ajouter des lignes en pointillés (projection du point i)
  geom_point(data = individus, aes(x = x, y = y), size = 3, col= "#398d55") +
  
  # Ajouter les points en pointillés (projection du point i)
  geom_segment(data = individus_dessin, aes(x = x, y = y, xend = xend, yend = yend), linetype = "dashed") +
  
  # Ajouter des labels mathématiques pour l'es distances l'espace
  geom_text(aes(x = 0.3, y = 2), label = as.character(expression(R^p)),col="#F7A913", size = 5) +
  
  # Ajouter le nom de l'axe
  geom_text(aes(x = -1.2, y = -2), label = as.character(expression(Delta)), vjust = -0.8, size = 5) +

  # Ajouter le nom des individus
  geom_text(data= individus_dessin, aes(x = xend, y =yend),  label = paste0("p[", 1:3, "]^Delta"), parse = TRUE, vjust = -0.8, size = 5) +
  geom_text(data= individus_dessin, aes(x = x, y =y),  label = paste0("x[", 1:3, "]"), parse = TRUE, vjust = -0.8, size = 5, col = "#398d55") +
  
  # Ajouter l'origine O = G
  geom_text(aes(x = 0.15, y = -0.1), label = "G", vjust = -0.8, size = 5) +
  geom_point(aes(x = 0, y = 0),  size = 2) +
  
  # Ajouter l'origine O = G
  geom_point(data = individus_dessin, aes(x = xend, y = yend),  size = 2) +
  
  # Ajuster le thème
  theme_minimal()  +
  
  coord_fixed() +  # Conserver un rapport d'aspect fixe pour les axes

  # Ajuster le thème
  theme (axis.title=element_blank(),
         axis.text=element_blank(),
         axis.ticks=element_blank(),
         panel.grid = element_blank())

```
:::
:::::


### Pour perdre le moins d'information possible 


[Identifier $\Delta$ tel que $I_{\Delta}$ soit minimale]{.rouge}

Ce qui revient à l'axe $\Delta$ qui assure que la projection sur
$\Delta$ déforme le moins possible le nuage de points.

Dans le cadre de l'ACP, on veut construire une ensemble d'axes
orthogonaux (une nouvelle base de ${\mathbb{R}}^p$), de façon à ce que

-   la projection sur le premier axe, soit le meilleur résumé du nuage
    de points en une dimension,
-   le deuxième axe est orthogonal au premier et représente "le deuxième
    meileur choix" .... dans un sens que l'on va définir
-   le troisième ...

### Rappel projection orthogonale

::::: columns
::: {.column width="55%"}
```{r proj_prodscalaire}
#! message: false
#! warning: false



# Définition du point x
point_a <- c(3, 0.8)
u <- c(sqrt(2)/2, sqrt(2)/2)  # vecteur direteur de la droite

# Calcul de la projection orthogonale de x sur Delta
a_proj <- sum(point_a*u)*u

# Création d'un data frame pour ggplot2
data <- data.frame(
  x = c(0,  point_a[1], a_proj[1]),
  y = c(0,  point_a[2], a_proj[2]))
label_dta = as.character(c(expression(O), expression(a), expression(a[u])))


scale_f = max(point_a/u) +1
# Plot avec ggplot2
ggplot(data) +
  geom_point(aes(x, y), color = "#33658A", size = 3) +
  geom_text(aes(x, y), label = label_dta, hjust = -0.4, vjust = -0.8) +
  geom_text(x=u[1]/2, y=u[2]/2, label = "u", hjust = 0.4, vjust = -0.8, color = "#C94326") +
  geom_segment(aes(x = 0, y = 0, xend = scale_f*u[1], yend = scale_f*u[2]), 
               color = "gray80", linetype = "dashed") +
  geom_segment(aes(x = 0, y = 0, xend = u[1], yend = u[2]), 
               color = "#C94326", linetype = "dashed", arrow = arrow(length = unit(0.2, "cm"))) +
  geom_segment(aes(x = point_a[1], y = point_a[2], xend = a_proj[1], yend = a_proj[2]),
               color = "#398d55") +  
  geom_segment(aes(x = point_a[1], y = point_a[2], xend = 0, yend = 0),
               color = "#398d55", linetype = "dotted") +
  labs(title = "Projection orthogonale d'un point A sur un sous espace affine", 
       x = "X", y = "Y") +
  theme_minimal() +
  coord_fixed() +
  theme (axis.title=element_blank(),
         axis.text=element_blank(),
         axis.ticks=element_blank(),
         panel.grid = element_blank())

```
:::

::: {.column width="40%"}
-   **Produit scalaire** : Soient deux élements $\boldsymbol{x}$ et
    $\boldsymbol{y}$ de $\mathbb{R}^p$, le produit scalaire est noté
    $<\boldsymbol{x},\boldsymbol{y}>$ et
    $<\boldsymbol{x},\boldsymbol{y}>=\sum_{i=1}^p x_i y_i = \boldsymbol{x}^\top \boldsymbol{y}.$

-   **Orthogonalité** Soient deux élements $\boldsymbol{x}$ et
    $\boldsymbol{y}$ de $\mathbb{R}^p$, on dit que $\boldsymbol{x}$ et
    $\boldsymbol{y}$ sont orthogonaux (noté
    $\boldsymbol{x}\perp \boldsymbol{y}$) si
    $<\boldsymbol{x},\boldsymbol{y}> = \boldsymbol{x}^\top  \boldsymbol{y}=0$.

-   **Projection orthogonale** On note $\boldsymbol{a}_u$ le projeté de
    $\boldsymbol{a}$ sur la droite $\Delta$ définit par son vecteur
    directeur unitaire $\boldsymbol{u}$ et passant par l'origine
    $$\boldsymbol{a}_u = < \boldsymbol{a}, \boldsymbol{u} > \boldsymbol{u} = (\boldsymbol{a}^\top \boldsymbol{u})\,  \boldsymbol{u}.$$
    Le vecteur $\boldsymbol{a_u}$ est orthogonal à
    $\boldsymbol{a}-\boldsymbol{a_u}$:
    $$< \boldsymbol{a_u}, \boldsymbol{a}-\boldsymbol{a_u}> = \left ((\boldsymbol{a}^\top \boldsymbol{u}) \boldsymbol{u}\right)^\top \left ( \boldsymbol{a} -  (\boldsymbol{a}^\top \boldsymbol{u})\,  \boldsymbol{u} \right)=(\boldsymbol{a}^\top \boldsymbol{u}) (\boldsymbol{u}^\top \boldsymbol{a}) - (\boldsymbol{a}^\top \boldsymbol{u})^2 \boldsymbol{u}^\top \boldsymbol{u} =0  $$
:::
:::::
:::::::::

## L'inertie par rapport à un sous espace affine

-   **Espace orthogonal** Soit $E$ un sous-espace vectoriel de
    $\mathbb{R}^p$. On definit
    $E^\perp=\{\boldsymbol{x}\in \mathbb{R}^p:\; \forall \boldsymbol{y}\in E,\; \boldsymbol{x}\perp \boldsymbol{y}\}$.

::: panel-tabset
### Exemple

Dans ${\mathbb{R}}^2$, on considère le sous espace vectoriel $E$, tel
que
$$ E =\left \lbrace  \boldsymbol{x}=\begin{pmatrix} x_1 &  x_2 \end{pmatrix}^\top \in {\mathbb{R}}^2 : x_1 = x_2  \right \rbrace $$
$E$ est la droite d'équation $y=x$.

Qui est $E^\perp$ ?

### Solution

Soit $\boldsymbol{y}\in E^\perp,$ alors

\begin{align}
0 & = \boldsymbol{x}^\top \boldsymbol{y}\\
  & = \begin{pmatrix} x_1 &  x_2 \end{pmatrix} \begin{pmatrix} y_1 \\  y_2 \end{pmatrix}\\
  & = x_1 y_1 + x_2 y_2 \\
  & = x_1 (y_1 + y_2) \quad (\boldsymbol{x}\in E \Rightarrow x_1 =x_2) \\
\end{align}

$$E^\perp =  \left \lbrace  \boldsymbol{y}=\begin{pmatrix} y_1 &  y_2 \end{pmatrix}^\top \in {\mathbb{R}}^2 : y_1 + y_2 = 0 \right \rbrace  $$
:::

. . .

::: {.callout-note icon="false" appearance="minimal"}
### Definition 3

L'inertie *par rapport à un sous espace vectoriel* $E$ est définie par
$$I_{E} = \frac{1}{n} \sum_{i=1}^n \lVert\boldsymbol{x}_{i} - \boldsymbol{p_i}^{E}\rVert^2 = \frac{1}{n} \sum_{i=1}^n\sum_{k=1}^p  (x_i^k -p^{k,E}_i)^2, \quad \mbox{où }\  \boldsymbol{p_i}^{E} = argmin_{\boldsymbol{y}\in E} d(\boldsymbol{y}, \boldsymbol{x}_{i}), \mbox{i.e. projeté orthogonal de } \boldsymbol{x_i} \mbox{ sur }E.$$
:::

C'est [l'inertie perdue]{.rouge} lorsque l'on résume le nuage de points
à sa projection sur le sous espace $E$.

## Décomposition de l'inertie

::: lemme
Soit $E$ un sous espace vectoriel de ${\mathbb{R}}^p$, alors
$$I = I_E + I_{E^\perp}.$$
:::

[Preuve]{.rouge}

::::: columns
::: {.column width="30%"}
Un dessin vaut mieux qu'un long discours et Pythagore est ton ami !

$$d(\class{alea}{\boldsymbol{x}_{i}}, O)^2 = d(\boldsymbol{x}_{i}, \class{bleu}{\boldsymbol{x}_{i}^E})^2  +  d(\class{alea}{\boldsymbol{x}_{i}}, \class{rouge}{\boldsymbol{x}_{i}^{E^\perp}})^2.$$

\begin{align}
 I & = \frac{1}{n} \sum_{i=1}^n d(\class{alea}{\boldsymbol{x}_{i}}, O)^2 \\
   & = \frac{1}{n} \sum_{i=1}^n d(\class{alea}{\boldsymbol{x}_{i}}, \class{bleu}{\boldsymbol{x}_{i}^E})^2   +  \frac{1}{n} \sum_{i=1}^n d(\class{alea}{\boldsymbol{x}_{i}}, \class{rouge}{\boldsymbol{x}_{i}^{E^\perp}})^2 \\
   & = \class{bleu}{I_E} + \class{rouge}{I_{E^\perp}}
\end{align}
:::

::: {.column width="65%"}
```{r inertie_decomp}
individus <- data.frame(
  x = c(1.5, -0.5, -1),   # Coordonnées des points individuels
  y = c(0.9, 1, -0.5)
) %>% 
  mutate(x = x - mean(x), y = y -mean(y))


u = c(1,2)
v = c(2, -1)

norme_u = sum(u^2)
norme_v = sum(v^2)

ind_proj_u <- (as.matrix(individus)%*% as.matrix(u, ncol= 1)/(norme_u)) %*% matrix(u, ncol = 2, nrow=1)
ind_proj_u <- as.data.frame(ind_proj_u) %>% 
  rename(xproj_u= V1, yproj_u=V2)
ind_proj_v <- (as.matrix(individus)%*% as.matrix(v, ncol= 1)/(norme_v)) %*% matrix(v, ncol = 2, nrow=1)
ind_proj_v <- as.data.frame(ind_proj_v) %>% 
  rename(xproj_v= V1, yproj_v=V2)

individus_dessin <- cbind(individus, ind_proj_u , ind_proj_v) %>% as.data.frame()

# Schéma avec ggplot
ggplot() +
  
  coord_fixed() +  # Conserver un rapport d'aspect fixe pour les axes
  
  # Tracer Delta
  geom_segment(aes(x = -u[1], y = -u[2], xend = u[1], yend = u[2]), arrow = arrow(length = unit(0.3, "cm")), size = 0.5, col = "#33658A",  linetype = "dotted") +  # E
  # Tracer Delta\perp
  geom_segment(aes(x = -v[1], y = -v[2], xend = v[1], yend = v[2]), arrow = arrow(length = unit(0.3, "cm")), size = 0.5, linetype = "dashed", col = "#C94326") +  # E^\perp
  
  # Ajouter des lignes en pointillés (projection du point i)
  geom_point(data = individus, aes(x = x, y = y), size = 3, col= "#398d55") +
  
  # Ajouter les points en pointillés (projection du point i)
  geom_segment(data = individus_dessin, aes(x = x, y = y, xend = xproj_u, yend = yproj_u), col = "#33658A", linetype = "dotted") +
  geom_point(data = individus_dessin, aes(x = xproj_u, y = yproj_u), size = 3, col= "#33658A", size= 2) +
  
  # Ajouter les points en pointillés (projectionsur E^\perp)
  geom_segment(data = individus_dessin, aes(x = x, y = y, xend = xproj_v, yend = yproj_v), col = "#C94326", linetype = "dashed") +
  geom_point(data = individus_dessin, aes(x = xproj_v, y = yproj_v), size = 3, col= "#C94326", size= 2) +
  
  
  # Ajouter des labels mathématiques pour l'es distances l'espace
  geom_text(aes(x = 0.3, y = 2), label = as.character(expression(R^p)),col="#F7A913", size = 5) +
  
  # Ajouter le nom de l'axe
  geom_text(aes(x = -1.2, y = -2), label = "E", vjust = -0.8, col = "#33658A", size = 5) +
  geom_text(aes(x = -v[1], y = -v[2]), label = as.character(expression(E^"\u22A5")), vjust = -0.8, col = "#C94326", size = 5) +
  
  # Ajouter l'origine O = G
  geom_text(aes(x = 0.15, y = -0.1), label = "O", vjust = -0.8, size = 5) +
  geom_point(aes(x = 0, y = 0),  size = 2) +
  
  # Ajuster le thème
  theme_minimal()  +

  # Ajuster le thème
  theme (axis.title=element_blank(),
         axis.text=element_blank(),
         axis.ticks=element_blank(),
         panel.grid = element_blank())

```
:::
:::::

## Principe de la décomposition à venir

1.  Identifier le vecteur $\boldsymbol{u_1}$ de ${\mathbb{R}}^p$, tel
    que $I_{E_1}$ soit minimale avec
    $E_1=\left \lbrace \lambda \boldsymbol{u_1}, \lambda \in {\mathbb{R}}\right\rbrace,$

2.  Dans $E_1^\perp$, identifier le vecteur $\boldsymbol{u_2}$ de
    ${\mathbb{R}}^p$, tel que $I_{E_2}$ soit minimale avec
    $E_2=\left \lbrace \lambda \boldsymbol{u_2}, \lambda \in {\mathbb{R}}\right\rbrace,$

3.  Dans $\left (  E_1 \oplus E_2 \right)^\perp$, identifier le vecteur
    $\boldsymbol{u_3}$ de ${\mathbb{R}}^p$, tel que ....

...

Finalement on aura la décomposition

$$I= I_{E_1} + I_{E_2} + \ldots + I_{E_p}, \quad \mbox{avec } I_{E_1} \leq I_{E_2} \leq \ldots \leq I_{E_p}$$

